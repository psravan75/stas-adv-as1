{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "  1. Explain the properties of the F-distribution.\n",
        "\n",
        "Properties of the F-Distribution\n",
        "The F-distribution is a continuous probability distribution that arises in statistical tests, particularly in ANOVA (Analysis of Variance) and hypothesis testing of variances. It is used to compare two variances and determine if they are significantly different.\n",
        "\n",
        "Key Properties of the F-Distribution\n",
        "Non-Negative Values Only\n",
        "\n",
        "The F-distribution is always positive because it represents a ratio of variances, which are always non-negative.\n",
        "𝐹\n",
        "=\n",
        "𝑆\n",
        "1\n",
        "2\n",
        "𝑆\n",
        "2\n",
        "2\n",
        "F=\n",
        "S\n",
        "2\n",
        "2\n",
        "​\n",
        "\n",
        "S\n",
        "1\n",
        "2\n",
        "​\n",
        "\n",
        "​\n",
        " , where\n",
        "𝑆\n",
        "1\n",
        "2\n",
        "S\n",
        "1\n",
        "2\n",
        "​\n",
        "  and\n",
        "𝑆\n",
        "2\n",
        "2\n",
        "S\n",
        "2\n",
        "2\n",
        "​\n",
        "  are sample variances.\n",
        "Right-Skewed\n",
        "\n",
        "The F-distribution is not symmetrical; it is positively skewed (longer tail on the right).\n",
        "As degrees of freedom increase, the shape becomes more symmetric and approaches a normal distribution.\n",
        "Defined by Two Degrees of Freedom (df₁, df₂)\n",
        "\n",
        "df₁ (numerator degrees of freedom): Related to the variance of the first sample.\n",
        "df₂ (denominator degrees of freedom): Related to the variance of the second sample.\n",
        "Example: In an ANOVA test,\n",
        "𝑑\n",
        "𝑓\n",
        "1\n",
        "=\n",
        "𝑘\n",
        "−\n",
        "1\n",
        "df\n",
        "1\n",
        "​\n",
        " =k−1 (number of groups minus one), and\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        "=\n",
        "𝑁\n",
        "−\n",
        "𝑘\n",
        "df\n",
        "2\n",
        "​\n",
        " =N−k (total observations minus number of groups).\n",
        "Mean and Variance Depend on Degrees of Freedom\n",
        "\n",
        "Mean of F-distribution:\n",
        "𝐸\n",
        "(\n",
        "𝐹\n",
        ")\n",
        "=\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        "−\n",
        "2\n",
        ",\n",
        "for\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        ">\n",
        "2\n",
        "E(F)=\n",
        "df\n",
        "2\n",
        "​\n",
        " −2\n",
        "df\n",
        "2\n",
        "​\n",
        "\n",
        "​\n",
        " ,for df\n",
        "2\n",
        "​\n",
        " >2\n",
        "Variance of F-distribution:\n",
        "Var\n",
        "(\n",
        "𝐹\n",
        ")\n",
        "=\n",
        "2\n",
        "(\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        ")\n",
        "2\n",
        "(\n",
        "𝑑\n",
        "𝑓\n",
        "1\n",
        "+\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        "−\n",
        "2\n",
        ")\n",
        "𝑑\n",
        "𝑓\n",
        "1\n",
        "(\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        "−\n",
        "2\n",
        ")\n",
        "2\n",
        "(\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        "−\n",
        "4\n",
        ")\n",
        ",\n",
        "for\n",
        "𝑑\n",
        "𝑓\n",
        "2\n",
        ">\n",
        "4\n",
        "Var(F)=\n",
        "df\n",
        "1\n",
        "​\n",
        " (df\n",
        "2\n",
        "​\n",
        " −2)\n",
        "2\n",
        " (df\n",
        "2\n",
        "​\n",
        " −4)\n",
        "2(df\n",
        "2\n",
        "​\n",
        " )\n",
        "2\n",
        " (df\n",
        "1\n",
        "​\n",
        " +df\n",
        "2\n",
        "​\n",
        " −2)\n",
        "​\n",
        " ,for df\n",
        "2\n",
        "​\n",
        " >4\n",
        "Used for Hypothesis Testing\n",
        "\n",
        "The F-test compares two sample variances to check if they are significantly different.\n",
        "It is used in ANOVA (Analysis of Variance), Regression Analysis, and Variance Ratio Tests.\n",
        "Real-World Applications of the F-Distribution\n",
        "✔ ANOVA (Analysis of Variance) – Used to test if three or more population means are equal.\n",
        "✔ Comparing Two Population Variances – Checks if two samples come from populations with equal variances.\n",
        "✔ Regression Analysis – Determines if the overall regression model is significant.\n",
        "\n"
      ],
      "metadata": {
        "id": "MWNPaZk5rf-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MdilukgsFCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
        "\n",
        "Statistical Tests Using the F-Distribution\n",
        "The F-distribution is primarily used in statistical tests that involve comparing variances or determining relationships among multiple variables. The key tests where the F-distribution is applied include:\n",
        "\n",
        "1. Analysis of Variance (ANOVA)\n",
        "📌 Purpose: To compare the means of three or more groups to determine if at least one differs significantly.\n",
        "\n",
        "🔹 Why the F-distribution?\n",
        "\n",
        "ANOVA calculates the ratio of between-group variance to within-group variance.\n",
        "Since variances are always positive, and we are comparing ratios of variances, the F-distribution is ideal.\n",
        "🔹 Example:\n",
        "A company tests three different training programs to see if they impact employee performance differently. ANOVA with the F-test helps determine whether there is a significant difference between the three groups.\n",
        "\n",
        "2. Regression Analysis (Overall Model Significance Test)\n",
        "📌 Purpose: To determine if a regression model is significant by testing if at least one predictor variable explains a significant proportion of variation in the dependent variable.\n",
        "\n",
        "🔹 Why the F-distribution?\n",
        "\n",
        "The F-test in regression compares the explained variance (due to regression) to the unexplained variance (due to error).\n",
        "The test ensures that the regression coefficients are not all zero, meaning the model has predictive power.\n",
        "🔹 Example:\n",
        "A researcher builds a model predicting house prices based on size, location, and number of bedrooms. The F-test checks if these factors collectively explain price variation.\n",
        "\n",
        "3. F-Test for Comparing Two Variances\n",
        "📌 Purpose: To test if two populations have equal variances (homogeneity of variance).\n",
        "\n",
        "🔹 Why the F-distribution?\n",
        "\n",
        "The test statistic is the ratio of two sample variances\n",
        "𝐹\n",
        "=\n",
        "𝑆\n",
        "1\n",
        "2\n",
        "𝑆\n",
        "2\n",
        "2\n",
        "F=\n",
        "S\n",
        "2\n",
        "2\n",
        "​\n",
        "\n",
        "S\n",
        "1\n",
        "2\n",
        "​\n",
        "\n",
        "​\n",
        " , which follows an F-distribution.\n",
        "🔹 Example:\n",
        "A manufacturer tests two different machines producing metal parts to check if their variability in size is the same. If the variances differ significantly, one machine may be more consistent than the other.\n",
        "\n",
        "4. Chow Test (Structural Break Test in Regression)\n",
        "📌 Purpose: To determine whether two regression models differ significantly, often used in time-series or economic data.\n",
        "\n",
        "🔹 Why the F-distribution?\n",
        "\n",
        "It compares the sum of squared residuals (SSR) from different regression models, using an F-statistic.\n",
        "🔹 Example:\n",
        "An economist examines whether a policy change in 2008 significantly altered the relationship between inflation and GDP growth.\n",
        "\n"
      ],
      "metadata": {
        "id": "cG9m6SFLsFdz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CG_OJkVfsTKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3. What are the key assumptions required for conducting an F-test to compare the variances of two\n",
        "populations?\n",
        "\n",
        "Key Assumptions for Conducting an F-Test to Compare Two Population Variances\n",
        "An F-test for variances is used to determine if two populations have equal variances. To ensure the test is valid, the following key assumptions must be met:\n",
        "\n",
        "1. The Populations Follow a Normal Distribution\n",
        "📌 Why?\n",
        "\n",
        "The F-test is highly sensitive to deviations from normality.\n",
        "If populations are not normally distributed, the test may lead to incorrect conclusions.\n",
        "🔹 Solution:\n",
        "\n",
        "Use a Shapiro-Wilk test or Kolmogorov-Smirnov test to check for normality before applying the F-test.\n",
        "If normality is violated, consider using Levene’s test or Brown-Forsythe test, which are less sensitive to non-normality.\n",
        "2. The Samples Are Randomly Selected\n",
        "📌 Why?\n",
        "\n",
        "The test assumes that both samples are randomly drawn from their respective populations.\n",
        "Non-random sampling can introduce bias and make results unreliable.\n",
        "🔹 Solution:\n",
        "\n",
        "Ensure proper random sampling techniques are used when collecting data.\n",
        "3. The Samples Are Independent\n",
        "📌 Why?\n",
        "\n",
        "The F-test assumes that the two samples do not influence each other.\n",
        "If the samples are dependent (e.g., paired or matched data), the F-test is inappropriate.\n",
        "🔹 Solution:\n",
        "\n",
        "If samples are related (e.g., before-and-after measurements on the same subjects), use a paired test instead of an F-test.\n",
        "4. The Populations Must Have the Same Scale of Measurement\n",
        "📌 Why?\n",
        "\n",
        "The variances being compared must be measured on the same scale (e.g., both in millimeters, not one in millimeters and the other in inches).\n",
        "🔹 Solution:\n",
        "\n",
        "Standardize the measurement units if necessary before conducting the test.\n"
      ],
      "metadata": {
        "id": "SzMop4rDsXJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Ndh1kX4siXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4. What is the purpose of ANOVA, and how does it differ from a t-test?\n",
        "\n",
        "Purpose of ANOVA & Differences from a t-Test\n",
        "What is ANOVA?\n",
        "📌 ANOVA (Analysis of Variance) is a statistical test used to compare three or more group means to determine if there is a significant difference among them.\n",
        "\n",
        "🔹 Purpose:\n",
        "\n",
        "Determines if at least one group mean is different from others.\n",
        "Uses the F-distribution to compare the variance between groups and variance within groups.\n",
        "🔹 Types of ANOVA:\n",
        "\n",
        "One-Way ANOVA – Compares means of one independent variable across multiple groups.\n",
        "Two-Way ANOVA – Compares means of two independent variables, allowing for interaction effects.\n",
        "Repeated Measures ANOVA – Used when the same subjects are measured multiple times.\n",
        "\n",
        "Why Use ANOVA Instead of Multiple t-Tests?\n",
        "Running multiple t-tests increases the Type I error rate (false positives).\n",
        "ANOVA controls this error and provides a single test to determine if any group differs.\n",
        "Example Scenario\n",
        "✔ t-Test Example:\n",
        "A researcher wants to compare test scores between two teaching methods (A vs. B). A t-test is appropriate.\n",
        "\n",
        "✔ ANOVA Example:\n",
        "A researcher compares test scores across three teaching methods (A, B, C). Since there are more than two groups, ANOVA is needed."
      ],
      "metadata": {
        "id": "gPbZjsfysisa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C77uZKQKsv6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more\n",
        "than two groups\n",
        "\n",
        "When and Why to Use a One-Way ANOVA Instead of Multiple t-Tests\n",
        "📌 When to Use One-Way ANOVA\n",
        "One-way ANOVA is used when:\n",
        "✔ Comparing means of three or more groups (e.g., different treatment groups, age groups, or product types).\n",
        "✔ The dependent variable is continuous (e.g., test scores, revenue, weight).\n",
        "✔ The independent variable is categorical with three or more levels (e.g., \"Low\", \"Medium\", \"High\").\n",
        "✔ The data meets ANOVA assumptions: normality, independence, and equal variance (homogeneity).\n",
        "\n",
        "📌 Why Use One-Way ANOVA Instead of Multiple t-Tests?\n",
        "1️⃣ Controls Type I Error (False Positives)\n",
        "Each t-test has a 5% chance of a false positive (if using a significance level of 0.05).\n",
        "If you compare three groups, you need three t-tests:\n",
        "A vs. B\n",
        "A vs. C\n",
        "B vs. C\n",
        "With four groups, you need six t-tests:\n",
        "A vs. B, A vs. C, A vs. D, B vs. C, B vs. D, C vs. D\n",
        "The more t-tests you run, the higher the probability of a false positive (Type I error).\n",
        "ANOVA performs a single test, keeping the error rate controlled.\n",
        "✔ Example: If you conduct five t-tests, the overall risk of making a Type I error is much higher than 5%! ANOVA prevents this issue.\n",
        "\n",
        "2️⃣ More Efficient & Comprehensive\n",
        "Instead of running multiple t-tests separately, ANOVA tests all groups at once, making it faster and easier to interpret.\n",
        "If ANOVA finds a significant difference, you can perform post hoc tests (e.g., Tukey’s HSD) to determine which specific groups differ.\n",
        "✔ Example: Comparing the effects of three diets on weight loss. One-way ANOVA tells us if there’s any difference at all, and post hoc tests tell us which diets differ.\n",
        "\n",
        "3️⃣ Works for More Than Two Groups\n",
        "A t-test only works for comparing two means. If you have three or more groups, ANOVA is required.\n",
        "If ANOVA finds a significant difference, you can further investigate using post hoc comparisons.\n",
        "✔ Example: Testing three different fertilizers (A, B, and C) on plant growth. ANOVA determines if at least one fertilizer performs differently."
      ],
      "metadata": {
        "id": "y6LZFeHKswba"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0cxao9gs99D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
        "How does this partitioning contribute to the calculation of the F-statistic?\n",
        "\n",
        "Partitioning Variance in ANOVA & F-Statistic Calculation\n",
        "ANOVA (Analysis of Variance) works by partitioning the total variance in a dataset into two components:\n",
        "\n",
        "1️⃣ Between-Group Variance (Variance due to treatment effects)\n",
        "2️⃣ Within-Group Variance (Variance due to random error)\n",
        "\n",
        "This partitioning helps determine whether group means differ significantly.\n",
        "\n",
        "📌 Partitioning Variance in ANOVA\n",
        "The Total Variance in the data is divided as follows:\n",
        "\n",
        "Total Variance\n",
        "=\n",
        "Between-Group Variance\n",
        "+\n",
        "Within-Group Variance\n",
        "Total Variance=Between-Group Variance+Within-Group Variance\n",
        "🔹 Total Sum of Squares (SST)\n",
        "Represents the total variation in the dataset. It is calculated as:\n",
        "\n",
        "𝑆\n",
        "𝑆\n",
        "𝑇\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "𝑖\n",
        "𝑗\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        "total\n",
        ")\n",
        "2\n",
        "SST=∑(X\n",
        "ij\n",
        "​\n",
        " −\n",
        "X\n",
        "ˉ\n",
        "  \n",
        "total\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "where\n",
        "𝑋\n",
        "𝑖\n",
        "𝑗\n",
        "X\n",
        "ij\n",
        "​\n",
        "  is an individual observation, and\n",
        "𝑋\n",
        "ˉ\n",
        "total\n",
        "X\n",
        "ˉ\n",
        "  \n",
        "total\n",
        "​\n",
        "  is the overall mean.\n",
        "\n",
        "🔹 Between-Group Sum of Squares (SSB)\n",
        "Represents the variation due to differences between group means. It is calculated as:\n",
        "\n",
        "𝑆\n",
        "𝑆\n",
        "𝐵\n",
        "=\n",
        "∑\n",
        "𝑛\n",
        "𝑗\n",
        "(\n",
        "𝑋\n",
        "ˉ\n",
        "𝑗\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        "total\n",
        ")\n",
        "2\n",
        "SSB=∑n\n",
        "j\n",
        "​\n",
        " (\n",
        "X\n",
        "ˉ\n",
        "  \n",
        "j\n",
        "​\n",
        " −\n",
        "X\n",
        "ˉ\n",
        "  \n",
        "total\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "where:\n",
        "\n",
        "𝑛\n",
        "𝑗\n",
        "n\n",
        "j\n",
        "​\n",
        "  = number of observations in group\n",
        "𝑗\n",
        "j\n",
        "𝑋\n",
        "ˉ\n",
        "𝑗\n",
        "X\n",
        "ˉ\n",
        "  \n",
        "j\n",
        "​\n",
        "  = mean of group\n",
        "𝑗\n",
        "j\n",
        "🔹 Within-Group Sum of Squares (SSW)\n",
        "Represents the variation within each group due to randomness (individual differences). It is calculated as:\n",
        "\n",
        "𝑆\n",
        "𝑆\n",
        "𝑊\n",
        "=\n",
        "∑\n",
        "(\n",
        "𝑋\n",
        "𝑖\n",
        "𝑗\n",
        "−\n",
        "𝑋\n",
        "ˉ\n",
        "𝑗\n",
        ")\n",
        "2\n",
        "SSW=∑(X\n",
        "ij\n",
        "​\n",
        " −\n",
        "X\n",
        "ˉ\n",
        "  \n",
        "j\n",
        "​\n",
        " )\n",
        "2\n",
        "\n",
        "where\n",
        "𝑋\n",
        "𝑖\n",
        "𝑗\n",
        "X\n",
        "ij\n",
        "​\n",
        "  is an individual observation in group\n",
        "𝑗\n",
        "j.\n",
        "\n",
        "📌 How This Helps Calculate the F-Statistic\n",
        "The F-statistic in ANOVA is the ratio of Between-Group Variance to Within-Group Variance:\n",
        "\n",
        "𝐹\n",
        "=\n",
        "Mean Square Between (MSB)\n",
        "Mean Square Within (MSW)\n",
        "F=\n",
        "Mean Square Within (MSW)\n",
        "Mean Square Between (MSB)\n",
        "​\n",
        "\n",
        "Where:\n",
        "\n",
        "MSB (Mean Square Between) =\n",
        "𝑆\n",
        "𝑆\n",
        "𝐵\n",
        "𝑑\n",
        "𝑓\n",
        "𝐵\n",
        "df\n",
        "B\n",
        "​\n",
        "\n",
        "SSB\n",
        "​\n",
        " , where\n",
        "𝑑\n",
        "𝑓\n",
        "𝐵\n",
        "=\n",
        "𝑘\n",
        "−\n",
        "1\n",
        "df\n",
        "B\n",
        "​\n",
        " =k−1 (number of groups - 1)\n",
        "MSW (Mean Square Within) =\n",
        "𝑆\n",
        "𝑆\n",
        "𝑊\n",
        "𝑑\n",
        "𝑓\n",
        "𝑊\n",
        "df\n",
        "W\n",
        "​\n",
        "\n",
        "SSW\n",
        "​\n",
        " , where\n",
        "𝑑\n",
        "𝑓\n",
        "𝑊\n",
        "=\n",
        "𝑁\n",
        "−\n",
        "𝑘\n",
        "df\n",
        "W\n",
        "​\n",
        " =N−k (total observations - number of groups)\n",
        "📌 Interpretation:\n",
        "\n",
        "If F is large, the variance between groups is much greater than the variance within groups → Suggests a significant difference.\n",
        "If F is close to 1, between-group variance is similar to within-group variance → No significant difference.\n"
      ],
      "metadata": {
        "id": "haAYSU57s-UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1z6hoYLNtLHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key\n",
        "differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
        "\n",
        "Classical (Frequentist) vs. Bayesian Approach to ANOVA\n",
        "Both frequentist ANOVA and Bayesian ANOVA are used to compare group means, but they differ in how they handle uncertainty, estimate parameters, and test hypotheses.\n",
        "📌 1. How They Handle Uncertainty\n",
        "Frequentist ANOVA\n",
        "Uncertainty is controlled using confidence intervals and p-values.\n",
        "Example: If\n",
        "𝑝\n",
        "<\n",
        "0.05\n",
        "p<0.05, we reject\n",
        "𝐻\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        " , but we cannot say how likely\n",
        "𝐻\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        "  is true.\n",
        "Bayesian ANOVA\n",
        "Uncertainty is expressed through probability distributions over parameters.\n",
        "Example: A Bayes factor tells us how much more likely one hypothesis is compared to another (e.g.,\n",
        "𝐵\n",
        "𝐹\n",
        "=\n",
        "5\n",
        "BF=5 means data is 5 times more likely under one model).\n",
        "📌 2. Parameter Estimation\n",
        "Frequentist Approach\n",
        "Estimates group means and variances using maximum likelihood estimation (MLE).\n",
        "Provides point estimates and confidence intervals but does not quantify belief about parameters.\n",
        "Bayesian Approach\n",
        "Estimates posterior distributions for means and variances.\n",
        "Uses prior knowledge + data to update beliefs.\n",
        "Example: Instead of just saying \"the mean of Group A is 10,\" it provides a probability distribution around 10.\n",
        "📌 3. Hypothesis Testing\n",
        "Frequentist (Null Hypothesis Significance Testing - NHST)\n",
        "Define null hypothesis (\n",
        "𝐻\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        " ): \"All group means are equal.\"\n",
        "Compute F-statistic and p-value.\n",
        "If\n",
        "𝑝\n",
        "<\n",
        "0.05\n",
        "p<0.05, reject\n",
        "𝐻\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        " .\n",
        "🔹 Problem: p-values do not measure evidence for or against\n",
        "𝐻\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        " —only how extreme the data are if\n",
        "𝐻\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        "  were true.\n",
        "\n",
        "Bayesian Hypothesis Testing\n",
        "Define prior probabilities for models.\n",
        "Compute posterior probabilities using Bayes’ theorem.\n",
        "Compare models using the Bayes Factor (BF):\n",
        "𝐵\n",
        "𝐹\n",
        ">\n",
        "1\n",
        "BF>1 → Evidence supports the alternative hypothesis.\n",
        "𝐵\n",
        "𝐹\n",
        "<\n",
        "1\n",
        "BF<1 → Evidence supports the null hypothesis.\n",
        "𝐵\n",
        "𝐹\n",
        ">\n",
        "10\n",
        "BF>10 → Strong evidence against\n",
        "𝐻\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        " .\n",
        "🔹 Advantage: Directly quantifies how much more likely one hypothesis is over another.\n",
        "\n",
        "📌 4. Handling Small Samples\n",
        "Frequentist ANOVA: Needs large sample sizes for stable estimates.\n",
        "Bayesian ANOVA: Works well even with small datasets because it incorporates prior information."
      ],
      "metadata": {
        "id": "iD_WhNg_tLf2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aDx5p-uRtcgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 8. Question: You have two sets of data representing the incomes of two different professions\n",
        " Profession A: [48, 52, 55, 60, 62\n",
        " Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
        "incomes are equal. What are your conclusions based on the F-test?\n",
        " Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
        " Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison"
      ],
      "metadata": {
        "id": "nD7F6tFctgIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Given income data\n",
        "profession_A = [48, 52, 55, 60, 62]\n",
        "profession_B = [45, 50, 55, 52, 47]\n",
        "\n",
        "# Calculate variances\n",
        "var_A = np.var(profession_A, ddof=1)  # Sample variance\n",
        "var_B = np.var(profession_B, ddof=1)  # Sample variance\n",
        "\n",
        "# Compute F-statistic\n",
        "F_statistic = var_A / var_B\n",
        "\n",
        "# Degrees of freedom\n",
        "df_A = len(profession_A) - 1\n",
        "df_B = len(profession_B) - 1\n",
        "\n",
        "# Compute p-value\n",
        "p_value = stats.f.cdf(F_statistic, df_A, df_B) * 2  # Two-tailed test\n",
        "\n",
        "# Print results\n",
        "print(f\"Variance of Profession A: {var_A:.2f}\")\n",
        "print(f\"Variance of Profession B: {var_B:.2f}\")\n",
        "print(f\"F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. The variances are not significantly different.\")\n"
      ],
      "metadata": {
        "id": "9a19KmRPthKo",
        "outputId": "0f8d62ea-a5b2-43d6-cbcc-aca4f0b6267e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of Profession A: 32.80\n",
            "Variance of Profession B: 15.70\n",
            "F-statistic: 2.0892\n",
            "p-value: 1.5070\n",
            "Conclusion: Fail to reject the null hypothesis. The variances are not significantly different.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7gWfaEstwFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
        "average heights between three different regions with the following data\n",
        " Region A: [160, 162, 165, 158, 164\n",
        " Region B: [172, 175, 170, 168, 174\n",
        " Region C: [180, 182, 179, 185, 183\n",
        " Task: Write Python code to perform the one-way ANOVA and interpret the results\n",
        " Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
      ],
      "metadata": {
        "id": "HEhRj3Fqt_Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Given height data\n",
        "region_A = [160, 162, 165, 158, 164]\n",
        "region_B = [172, 175, 170, 168, 174]\n",
        "region_C = [180, 182, 179, 185, 183]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "F_statistic, p_value = stats.f_oneway(region_A, region_B, region_C)\n",
        "\n",
        "# Print results\n",
        "print(f\"F-statistic: {F_statistic:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis. There is a statistically significant difference in average heights between the regions.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis. No significant difference in average heights between the regions.\")\n"
      ],
      "metadata": {
        "id": "Ddg6ElRSuAA3",
        "outputId": "68a7f436-030e-4aab-bdda-0e49086b0a68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 67.8733\n",
            "p-value: 0.0000\n",
            "Conclusion: Reject the null hypothesis. There is a statistically significant difference in average heights between the regions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JnLx_7ZuERu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}